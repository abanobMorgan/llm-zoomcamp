{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f085899-cd08-4549-944b-f0d54c6f9676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:24:22.352553Z",
     "iopub.status.busy": "2024-07-08T13:24:22.352163Z",
     "iopub.status.idle": "2024-07-08T13:24:25.848885Z",
     "shell.execute_reply": "2024-07-08T13:24:25.848012Z",
     "shell.execute_reply.started": "2024-07-08T13:24:22.352528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424ed07-bb90-4ec7-a01c-393a7b7a11c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:25:05.365272Z",
     "iopub.status.busy": "2024-07-08T13:25:05.364884Z",
     "iopub.status.idle": "2024-07-08T13:25:10.576639Z",
     "shell.execute_reply": "2024-07-08T13:25:10.575906Z",
     "shell.execute_reply.started": "2024-07-08T13:25:05.365247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "import minsearch\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline\n",
    "\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206023ad-9f06-4894-9b7a-5a1d019c1b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:25:10.579610Z",
     "iopub.status.busy": "2024-07-08T13:25:10.579103Z",
     "iopub.status.idle": "2024-07-08T13:25:10.785876Z",
     "shell.execute_reply": "2024-07-08T13:25:10.785090Z",
     "shell.execute_reply.started": "2024-07-08T13:25:10.579570Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f2d5882b880>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a8b7d2-8286-478b-93be-dfe612c0064a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:26:29.048537Z",
     "iopub.status.busy": "2024-07-08T13:26:29.048086Z",
     "iopub.status.idle": "2024-07-08T13:26:29.053216Z",
     "shell.execute_reply": "2024-07-08T13:26:29.052263Z",
     "shell.execute_reply.started": "2024-07-08T13:26:29.048510Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0c099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59dee7c1-0831-4191-ae40-1253807d9a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:26:30.532423Z",
     "iopub.status.busy": "2024-07-08T13:26:30.532028Z",
     "iopub.status.idle": "2024-07-08T13:26:30.538516Z",
     "shell.execute_reply": "2024-07-08T13:26:30.537599Z",
     "shell.execute_reply.started": "2024-07-08T13:26:30.532398Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2cfa554d30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "torch.random.manual_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23169d-70dc-4efb-9276-7b8ab1888c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:27:41.311368Z",
     "iopub.status.busy": "2024-07-08T13:27:41.310945Z",
     "iopub.status.idle": "2024-07-08T13:27:42.119202Z",
     "shell.execute_reply": "2024-07-08T13:27:42.118340Z",
     "shell.execute_reply.started": "2024-07-08T13:27:41.311340Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77a6832-4038-45dd-9b1d-f6e4b9e93486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:26:32.521307Z",
     "iopub.status.busy": "2024-07-08T13:26:32.520903Z",
     "iopub.status.idle": "2024-07-08T13:26:35.531558Z",
     "shell.execute_reply": "2024-07-08T13:26:35.530670Z",
     "shell.execute_reply.started": "2024-07-08T13:26:32.521282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea95b4924424ab99bdbecf08219891c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    padding_side=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3276fe8b-be76-4902-ae01-edaa5b9ae105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:26:36.247832Z",
     "iopub.status.busy": "2024-07-08T13:26:36.247433Z",
     "iopub.status.idle": "2024-07-08T13:26:36.257331Z",
     "shell.execute_reply": "2024-07-08T13:26:36.256668Z",
     "shell.execute_reply.started": "2024-07-08T13:26:36.247806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e258eaa-a3ee-41d5-9026-4abaa9c48b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:26:37.198799Z",
     "iopub.status.busy": "2024-07-08T13:26:37.198386Z",
     "iopub.status.idle": "2024-07-08T13:26:37.204596Z",
     "shell.execute_reply": "2024-07-08T13:26:37.203745Z",
     "shell.execute_reply.started": "2024-07-08T13:26:37.198773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"{doc['question']}\\n{doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = generator(prompt, max_length=500, temperature=0.7, top_p=0.95, num_return_sequences=1)\n",
    "    response_final = response[0]['generated_text']\n",
    "    return response_final[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "416e4fd3-1a99-49d3-983e-0b7dadb59c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T13:26:38.440882Z",
     "iopub.status.busy": "2024-07-08T13:26:38.440504Z",
     "iopub.status.idle": "2024-07-08T13:26:44.783498Z",
     "shell.execute_reply": "2024-07-08T13:26:44.782567Z",
     "shell.execute_reply.started": "2024-07-08T13:26:38.440855Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You can still join the course even if you discover it after the start date. You are eligible to submit the homeworks, but remember to meet the deadlines for the final projects. You can also follow the course materials at your own pace after it finishes, and start working on your final capstone project.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"I just discovered the course. Can I still join it?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a39091-e8e3-49e4-bc7f-5e22c009c3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7464158-2ecd-4c50-88ad-c92eb12183ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
