{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rdi/043764CF611486F91/NLP/llm-zoomcamp/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np \n",
    "from rouge import Rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv\"\n",
    "\n",
    "\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)\n",
    "df = df.iloc[:300]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Getting the embeddings model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"multi-qa-mpnet-base-dot-v1\"\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "answer_llm = df.iloc[0].answer_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.42244655\n"
     ]
    }
   ],
   "source": [
    "embedding_vector = embedding_model.encode(answer_llm)\n",
    "\n",
    "# Get the first value of the resulting vector\n",
    "first_value = embedding_vector[0]\n",
    "print(first_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Computing the dot product\n",
    "\n",
    "31.67430591583252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_llm = [embedding_model.encode(answer) for answer in df['answer_llm']]\n",
    "embeddings_orig = [embedding_model.encode(answer) for answer in df['answer_orig']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dot product between each pair of answers\n",
    "evaluations = []\n",
    "for emb_llm, emb_orig in zip(embeddings_llm, embeddings_orig):\n",
    "    dot_product = np.dot(emb_llm, emb_orig)\n",
    "    evaluations.append(dot_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.67430591583252\n"
     ]
    }
   ],
   "source": [
    "# Compute the 75th percentile of the scores\n",
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "print(percentile_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Computing the cosine\n",
    "\n",
    "0.8362348228693008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "for emb_llm, emb_orig in zip(embeddings_llm, embeddings_orig):\n",
    "    emb_llm_norm = normalize_vector(emb_llm)\n",
    "    emb_orig_norm = normalize_vector(emb_orig)\n",
    "    cosine_similarity = np.dot(emb_llm_norm, emb_orig_norm)\n",
    "    evaluations.append(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8362348228693008\n"
     ]
    }
   ],
   "source": [
    "# Compute the 75th percentile of the cosine similarities\n",
    "percentile_75_cosine = np.percentile(evaluations, 75)\n",
    "print(percentile_75_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Rouge\n",
    "\n",
    "0.45454544954545456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45454544954545456\n"
     ]
    }
   ],
   "source": [
    "rouge_scorer = Rouge()\n",
    "r = df.loc[df['document'] == '5170565b']\n",
    "\n",
    "score_q4 = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "\n",
    "\n",
    "\n",
    "# Extract the F1 score for ROUGE-1\n",
    "f1_score_rouge_1 = scores['rouge-1']['f']\n",
    "print(f1_score_rouge_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Average rouge score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35490034990035496\n"
     ]
    }
   ],
   "source": [
    "rouge_1 = score_q4['rouge-1']['f']\n",
    "rouge_2 = score_q4['rouge-2']['f']\n",
    "rouge_l = score_q4['rouge-l']['f']\n",
    "rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3\n",
    "print(rouge_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Average rouge score for all the data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1: 0.37884361657741583\n",
      "Average ROUGE-2 F1: 0.20696501983423318\n",
      "Average ROUGE-L F1: 0.35380746560786525\n",
      "Overall Average ROUGE score: 0.3132053673398381\n"
     ]
    }
   ],
   "source": [
    "rouge_1_f_scores = []\n",
    "rouge_2_f_scores = []\n",
    "rouge_l_f_scores = []\n",
    "\n",
    "# Loop through each record and compute ROUGE scores\n",
    "for idx, row in df.iterrows():\n",
    "    scores = rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]\n",
    "    rouge_1_f_scores.append(scores['rouge-1']['f'])\n",
    "    rouge_2_f_scores.append(scores['rouge-2']['f'])\n",
    "    rouge_l_f_scores.append(scores['rouge-l']['f'])\n",
    "\n",
    "# Compute the average ROUGE score for each type\n",
    "average_rouge_1_f = sum(rouge_1_f_scores) / len(rouge_1_f_scores)\n",
    "average_rouge_2_f = sum(rouge_2_f_scores) / len(rouge_2_f_scores)\n",
    "average_rouge_l_f = sum(rouge_l_f_scores) / len(rouge_l_f_scores)\n",
    "\n",
    "# Compute the overall average ROUGE score\n",
    "average_rouge = (average_rouge_1_f + average_rouge_2_f + average_rouge_l_f) / 3\n",
    "\n",
    "print(f\"Average ROUGE-1 F1: {average_rouge_1_f}\")\n",
    "print(f\"Average ROUGE-2 F1: {average_rouge_2_f}\")\n",
    "print(f\"Average ROUGE-L F1: {average_rouge_l_f}\")\n",
    "print(f\"Overall Average ROUGE score: {average_rouge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
